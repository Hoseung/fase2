{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9eae6b5",
   "metadata": {},
   "source": [
    "## 패키지 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79370e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb1ab32",
   "metadata": {},
   "source": [
    "## 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abb68e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/home/hoseung/Work/data/CIFAR10/\"\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 32\n",
    "valid_size = 0.2\n",
    "\n",
    "# normalize input data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "# (Download if needed and) load data\n",
    "train_data = datasets.CIFAR10(data_dir, train=True,\n",
    "                              download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10(data_dir, train=False,\n",
    "                             download=True, transform=transform)\n",
    "\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "# prepare data loaders (combine dataset and sampler)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler, num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
    "    sampler=valid_sampler, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers)\n",
    "\n",
    "# Image classes\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef7fd93",
   "metadata": {},
   "source": [
    "## pre-trained weight 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d193875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initialized CNN\n",
      "Weights from: ./Net_3fc2act.pt\n"
     ]
    }
   ],
   "source": [
    "# temporary parameters\n",
    "model = models.CNN_infer(\"./Net_3fc2act.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbe74b4",
   "metadata": {},
   "source": [
    "## Validation accuracy 측정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bd971c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 61.71875%\n"
     ]
    }
   ],
   "source": [
    "# Test only small portion\n",
    "iterations = 4\n",
    "dataloader_iterator = iter(test_loader)\n",
    "\n",
    "avg_acc=[]\n",
    "for i in range(iterations):\n",
    "    try:\n",
    "        data, target = next(dataloader_iterator)\n",
    "    except StopIteration:\n",
    "        dataloader_iterator = iter(dataloader)\n",
    "        data, target = next(dataloader_iterator)\n",
    "\n",
    "    results = model.eval(data)\n",
    "    accuracy = np.mean(np.array(target) == results.argmax(axis=1)) * 100\n",
    "    avg_acc.append(accuracy)\n",
    "\n",
    "print(\"Validation Accuracy: \" + str(np.mean(avg_acc)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa70d379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97478067",
   "metadata": {},
   "source": [
    "## 이 결과를 재현!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d7fb6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fase.cifar.functional import conv2d_eval_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb32c629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "x = data[:1]\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68c87d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights =  model._weights\n",
    "cvp = model._conv_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73c59a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad 2\n",
      "stride 1\n"
     ]
    }
   ],
   "source": [
    "w1 = weights['cvw1']\n",
    "b1 = weights['cvb1']\n",
    "#pad = cvp['p1']\n",
    "pad = 2\n",
    "stride = cvp['s1']\n",
    "\n",
    "print(\"pad\", pad)\n",
    "print(\"stride\", stride)\n",
    "out = conv2d_eval_torch(x, w1, b1, pad=pad, stride=stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "030bd606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 8, 32, 32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3281faaa",
   "metadata": {},
   "source": [
    "## FHE version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12a699b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 3, 5, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb3002d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image: width = 32, height = 32, # channels = 3, # img = 1\n",
      "Convolution Kernel: kernel width = 5, kernel_height = 5, channel in = 3, channel_out = 8\n"
     ]
    }
   ],
   "source": [
    "ch_out, ch_in, f_h, f_w = w1.shape\n",
    "\n",
    "n_x, x_ch_in, ww, hh = x.shape\n",
    "\n",
    "print(f\"Input image: width = {ww}, height = {hh}, # channels = {x_ch_in}, # img = {n_x}\")\n",
    "print(f\"Convolution Kernel: kernel width = {f_w}, kernel_height = {f_h}, channel in = {ch_in}, channel_out = {ch_out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb2e0c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded array length 1296\n"
     ]
    }
   ],
   "source": [
    "len_padded_array = (ww + f_w - 1) * (hh + f_h -1)\n",
    "xin_padded_array = np.zeros(len_padded_array)\n",
    "print(\"Padded array length\", len(xin_padded_array)) # Needs a Ciphertext of 2048 slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66edd5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "xin = np.zerod((f_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df139878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9abadb2",
   "metadata": {},
   "source": [
    "### Ctxt packing\n",
    "Algorithm 3 in Lee Junwoo +21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb1ace6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a0754ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = np.moveaxis(x.numpy()[0], 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe50288c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4339724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ww,hh,cc = x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1be10054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_sort(xx, N=15, slot_stride=1):\n",
    "    Ncipher = 2**N\n",
    "    \n",
    "    cc, ww,hh = xx.shape\n",
    "\n",
    "    packed =[]\n",
    "    for k in range(cc):\n",
    "        tmp = np.zeros(Ncipher) # Ncipher > ww*hh\n",
    "        for i in range(ww):\n",
    "            for j in range(hh):\n",
    "                tmp[i*ww + j] = xx[k,i,j]\n",
    "\n",
    "        packed.append(tmp)\n",
    "        \n",
    "    return (packed, ww, slot_stride, cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b5c9e811",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_tensor = tensor_sort(x.numpy()[0], 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1a6581e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 3, 5, 5)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "46cb6f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32768"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_tensor[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "61d1f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv \n",
    "W = w1\n",
    "N = 15\n",
    "Ncipher = 2**N\n",
    "ctk, l, slotstr, t = sorted_tensor\n",
    "stride = 1\n",
    "c_out, c_in, f_w, f_h = w1.shape\n",
    "\n",
    "L = l*slotstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "aabe0b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12591/1509342504.py:10: RuntimeWarning: divide by zero encountered in remainder\n",
      "  if (0 <= vv) * (vv <= l-1) * (np.mod(slotstr*stride, ip) == 0):\n"
     ]
    }
   ],
   "source": [
    "ct_h_list = []\n",
    "for h in range(c_out):\n",
    "    ct_h = np.zeros(Ncipher)\n",
    "    for k in range(c_in):\n",
    "        for (i,j) in zip(range(f_w), range(f_h)):\n",
    "            w = np.zeros(ww*hh)\n",
    "            for (ip,jp) in zip(range(ww), range(hh)):\n",
    "                vv = ip + i - int(np.floor(f_w/2))\n",
    "                #if (0 <= vv) * (vv <= l-1) * (np.mod(ip, slotstr*stride) == 0)\n",
    "                if (0 <= vv) * (vv <= l-1) * (np.mod(slotstr*stride, ip) == 0):\n",
    "                    w[ip*l+jp] = W[h,k,i,j]\n",
    "                \n",
    "            r = int(i - np.floor(f_w/2) * l + (j - np.floor(f_w/2)))\n",
    "            ct_h[:ww*hh] += w * np.roll(ctk[k], r*slotstr)[:ww*hh] #\n",
    "    ct_h_list.append(ct_h)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f5bf871b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(ct_h_list[5] != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ee39b968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(ctk[0][:1024] != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5ee135ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "1024\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "for ctx in ctk:\n",
    "    print(np.sum(ctx[:1024] !=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31b3f89",
   "metadata": {},
   "source": [
    "- packing 잘못 한 듯. 모두 처음 1024개만 값이 있는게 이상함. \n",
    "- 이상한 점은... packing 함수에 slotstr 변수가 안 쓰인다는 거. \n",
    "- 5.3 Convolution and BN 에서 stride=1 convolution은 Gazelle의 Single input single output (SISO) convolution을 썼다고 했음. \n",
    "\n",
    "tenseal의 im2col을 보면 packing 참고할 수 있을지도. (근데 좀 다른 방식임...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f15433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66e185dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[error] cannot open locale definition file `en': No such file or directory\n",
      "Qt: Session management error: Could not open network socket\n",
      "Icon theme \"Adwaita\" not found.\n",
      "Icon theme \"Adwaita\" not found.\n"
     ]
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "\n",
    "\n",
    "def make_dot(var, params=None):\n",
    "    if params is not None:\n",
    "        assert isinstance(params.values()[0], Variable)\n",
    "        param_map = {id(v): k for k, v in params.items()}\n",
    "\n",
    "    node_attr = dict(style=\"filled\", shape=\"box\", align=\"left\", fontsize=\"12\", ranksep=\"0.1\", height=\"0.2\")\n",
    "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"12,12\"))\n",
    "    seen = set()\n",
    "\n",
    "    def size_to_str(size):\n",
    "        return \"(\" + (\", \").join([\"%d\" % v for v in size]) + \")\"\n",
    "\n",
    "    def add_nodes(var):\n",
    "        if var not in seen:\n",
    "            if torch.is_tensor(var):\n",
    "                dot.node(str(id(var)), size_to_str(var.size()), fillcolor=\"orange\")\n",
    "                dot.edge(str(id(var.grad_fn)), str(id(var)))\n",
    "                var = var.grad_fn\n",
    "            if hasattr(var, \"variable\"):\n",
    "                u = var.variable\n",
    "                name = param_map[id(u)] if params is not None else \"\"\n",
    "                node_name = \"%s\\n %s\" % (name, size_to_str(u.size()))\n",
    "                dot.node(str(id(var)), node_name, fillcolor=\"lightblue\")\n",
    "            else:\n",
    "                dot.node(str(id(var)), str(type(var).__name__))\n",
    "            seen.add(var)\n",
    "            if hasattr(var, \"next_functions\"):\n",
    "                for u in var.next_functions:\n",
    "                    if u[0] is not None:\n",
    "                        dot.edge(str(id(u[0])), str(id(var)))\n",
    "                        add_nodes(u[0])\n",
    "            if hasattr(var, \"saved_tensors\"):\n",
    "                for t in var.saved_tensors:\n",
    "                    dot.edge(str(id(t)), str(id(var)))\n",
    "                    add_nodes(t)\n",
    "\n",
    "    add_nodes(var)\n",
    "    return dot\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import torchvision.models as models\n",
    "\n",
    "    inputs = torch.randn(1, 3, 224, 224)\n",
    "    resnet18 = models.resnet18()\n",
    "    y = resnet18(inputs)\n",
    "    # print(y)\n",
    "\n",
    "    g = make_dot(y)\n",
    "    g.view()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
