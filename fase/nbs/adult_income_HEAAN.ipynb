{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T13:49:16.741270Z",
     "start_time": "2020-06-06T13:49:16.719259Z"
    }
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from fase import HEAAN\n",
    "from fase import HEAAN as he\n",
    "from typing import List, Callable\n",
    "\n",
    "from fase import hnrf as hnrf\n",
    "\n",
    "from fase.hnrf.tree import NeuralTreeMaker\n",
    "from fase.hnrf import heaan_nrf \n",
    "from fase.hnrf.hetree_nrf import HomomorphicModel \n",
    "\n",
    "#import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrypt_print(ctx, n=20):\n",
    "    res1 = decrypt(secretKey, ctx)\n",
    "    print(res1[:n])\n",
    "    \n",
    "def decrypt(secretKey, enc):\n",
    "    featurized = scheme.decrypt(secretKey, enc)\n",
    "    arr = np.zeros(n, dtype=np.complex128)\n",
    "    featurized.__getarr__(arr)\n",
    "    return arr.real\n",
    "\n",
    "def encrypt(val):\n",
    "    ctxt = HEAAN.Ciphertext()#logp, logq, n)\n",
    "    vv = np.zeros(n) # Need to initialize to zero or will cause \"unbound\"\n",
    "    vv[:len(val)] = val\n",
    "    scheme.encrypt(ctxt, he.Double(vv), n, logp, logq)\n",
    "    del vv\n",
    "    return ctxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult income dataset\n",
    "\n",
    "Here we wll study the Adult Income Dataset and see how we can apply Homomorphic Random Forest to it.\n",
    "\n",
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
    "    header=None)\n",
    "\n",
    "df.columns = [\n",
    "    \"Age\", \"WorkClass\", \"fnlwgt\", \"Education\", \"EducationNum\",\n",
    "    \"MaritalStatus\", \"Occupation\", \"Relationship\", \"Race\", \"Gender\",\n",
    "    \"CapitalGain\", \"CapitalLoss\", \"HoursPerWeek\", \"NativeCountry\", \"Income\"\n",
    "]\n",
    "\n",
    "# df = df.sample(frac=0.1, random_state=1)\n",
    "train_cols = df.columns[0:-1]\n",
    "label = df.columns[-1]\n",
    "X = df[train_cols]\n",
    "y = df[label].apply(lambda x: 0 if x == \" <=50K\" else 1) #Turning response into 0 and 1\n",
    "\n",
    "seed = 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "Because we need our data to be in the range$[-1,1]$ at the beginning, we will create a preprocessing pipeline using sklearn Pipelines. \n",
    "\n",
    "It will apply a LabelEncoder on categorical columns, before using it in a MinMaxScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T13:49:24.602073Z",
     "start_time": "2020-06-06T13:49:24.570561Z"
    }
   },
   "outputs": [],
   "source": [
    "from fase.hnrf.preprocessing import Featurizer #임시로.. \n",
    "\n",
    "categorical_columns = [\"WorkClass\",\"Education\",\"MaritalStatus\", \"Occupation\", \"Relationship\", \n",
    "                       \"Race\", \"Gender\", \"NativeCountry\"]\n",
    "\n",
    "pipe = Featurizer(categorical_columns)\n",
    "\n",
    "X_train_normalized = pipe.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normalized.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look and check that input is in $[-1,1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Random Forest\n",
    "\n",
    "Now that data has been preprocessed, we can feed it to a Neural Random Forest.\n",
    "\n",
    "Here we can have a look at the activation function we will use, for instance sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:54:17.592037Z",
     "start_time": "2020-06-02T15:54:17.259957Z"
    }
   },
   "outputs": [],
   "source": [
    "from fase.hnrf.tree import NeuralRF#, SigmoidTreeMaker, TanhTreeMaker\n",
    "#from cryptotree.polynomials import plot_graph_function_approximation\n",
    "\n",
    "max_depth = 6\n",
    "\n",
    "dilatation_factor = 10\n",
    "polynomial_degree = 10\n",
    "\n",
    "#plot_graph_function_approximation(torch.sigmoid,\n",
    "#                                  dilatation_factor=dilatation_factor,polynomial_degree=polynomial_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:54:18.507864Z",
     "start_time": "2020-06-02T15:54:17.827608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=6, random_state=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=max_depth, random_state=0)\n",
    "rf.fit(X_train_normalized, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "crytotree에서는 서로 다른 크기/깊이의 tree를 가장 큰 tree에 맞춰 pad함.  (tree.py: L220)\n",
    "왜..? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:54:18.521339Z",
     "start_time": "2020-06-02T15:54:18.509104Z"
    }
   },
   "outputs": [],
   "source": [
    "#from cryptotree.RFconvertor import gen_l1, gen_l2\n",
    "#estimators = rf.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fase.hnrf.tree import NeuralTreeMaker\n",
    "from sklearn.tree import BaseDecisionTree\n",
    "#from functools import partial\n",
    "\n",
    "#from cryptotree.tree import *\n",
    "#from cryptotree.RFconvertor import *\n",
    "\n",
    "estimators = rf.estimators_\n",
    "\n",
    "my_tm_tanh = NeuralTreeMaker(torch.tanh, \n",
    "                            use_polynomial=True,\n",
    "                            dilatation_factor=dilatation_factor, \n",
    "                            polynomial_degree=polynomial_degree)\n",
    "\n",
    "#my_tanh_rf =NeuralRF(estimators[:2], my_tm_tanh)\n",
    "\n",
    "model =NeuralRF(estimators[:5], my_tm_tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = estimators[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features ==  14\n",
      "Number of questions == \n"
     ]
    }
   ],
   "source": [
    "print(\"Number of features == \", X_train.shape[1])\n",
    "print(\"Number of questions == \", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 57, 5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.comparator.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparator가 어떻게 생겼는지... \n",
    "model.comparator[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9e716fa220>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(model.comparator.data[:,:,0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid 트리는 성능이 매우 떨어짐. tanh는 얼추 비슷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:54:21.256637Z",
     "start_time": "2020-06-02T15:54:18.994382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy : 0.855497542997543\n",
      "Accuracy of tanh : 0.7560657248157249\n",
      "Match between tanh and original : 0.8433660933660934\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    #sigmoid_neural_pred = sigmoid_neural_rf(torch.tensor(X_train_normalized).float()).argmax(dim=1).numpy()\n",
    "    #tanh_neural_pred = tanh_neural_rf(torch.tensor(X_train_normalized).float()).argmax(dim=1).numpy()\n",
    "    #tanh_neural_pred = my_tanh_rf(torch.tensor(X_train_normalized).float()).argmax(dim=1).numpy()\n",
    "    tanh_neural_pred = model(torch.tensor(X_train_normalized).float()).argmax(dim=1).numpy()\n",
    "    \n",
    "pred = rf.predict(X_train_normalized)\n",
    "print(f\"Original accuracy : {(pred == y_train).mean()}\")\n",
    "\n",
    "#print(f\"Accuracy of sigmoid  : {(sigmoid_neural_pred == y_train).mean()}\")\n",
    "print(f\"Accuracy of tanh : {(tanh_neural_pred == y_train).mean()}\")\n",
    "\n",
    "#print(f\"Match between sigmoid and original : {(sigmoid_neural_pred == pred).mean()}\")\n",
    "print(f\"Match between tanh and original : {(tanh_neural_pred == pred).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is a discrepancy between the original Random Forest and the neural ones, especially for the sigmoid one.\n",
    "\n",
    "Nonetheless we can correct this error by finetuning the final layer of our neural networks to take into account the fact that due to using activation functions not sharp enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With finetuning\n",
    "\n",
    "Because we need to make sure that at each step of the Neural Network the output is in $[-1,1]$, to be able to use the polynomial approximation of the activation, we can only safely train the last layer.\n",
    "\n",
    "Here we first define our Pytorch Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:54:21.273755Z",
     "start_time": "2020-06-02T15:54:21.258166Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "import numpy as np\n",
    "\n",
    "class TabularDataset(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
    "        'Initialization'\n",
    "        self.X, self.y = X,y\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "\n",
    "        # Load data and get label\n",
    "        X = torch.tensor(self.X[index]).float()\n",
    "        y = torch.tensor(self.y[index])\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we split our training data into training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:54:21.322375Z",
     "start_time": "2020-06-02T15:54:21.274986Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=seed)\n",
    "X_train_normalized, X_valid_normalized, y_train, y_valid = train_test_split(pipe.transform(X_train), \n",
    "                                                                            y_train,\n",
    "                                                                            train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create the Pytorch dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:54:21.334525Z",
     "start_time": "2020-06-02T15:54:21.323394Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = TabularDataset(X_train_normalized, y_train.values)\n",
    "valid_ds = TabularDataset(X_valid_normalized, y_valid.values)\n",
    "\n",
    "bs = 128\n",
    "\n",
    "train_dl = data.DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "valid_dl = data.DataLoader(valid_ds, batch_size=bs)\n",
    "fix_dl = data.DataLoader(train_ds, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will just define the model, which is a sigmoid Neural Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:54:23.000386Z",
     "start_time": "2020-06-02T15:54:22.875406Z"
    }
   },
   "source": [
    "#tree_maker = tanh_tree_maker\n",
    "\n",
    "model =NeuralRF(rf.estimators_, tree_maker=my_tm_tanh)\n",
    "model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we only want to train the last layer, we will freeze the first two layers and check they are frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:54:23.243437Z",
     "start_time": "2020-06-02T15:54:23.227649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 57, 5]) False\n",
      "torch.Size([57, 5]) False\n",
      "torch.Size([58, 57, 5]) False\n",
      "torch.Size([58, 5]) False\n",
      "torch.Size([2, 58, 5]) True\n",
      "torch.Size([2, 5]) True\n"
     ]
    }
   ],
   "source": [
    "model.freeze_layer(\"comparator\")\n",
    "model.freeze_layer(\"matcher\")\n",
    "\n",
    "for p in model.parameters():\n",
    "    print(p.shape, p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:54:24.709134Z",
     "start_time": "2020-06-02T15:54:23.743899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy : 0.8568480660332085\n",
      "Accuracy : 0.7562146079278241\n",
      "Same output : 0.8418754199059411\n"
     ]
    }
   ],
   "source": [
    "pred = rf.predict(X_train_normalized)\n",
    "\n",
    "with torch.no_grad():\n",
    "    neural_pred = model(torch.tensor(X_train_normalized).float()).argmax(dim=1).numpy()\n",
    "\n",
    "print(f\"Original accuracy : {(pred == y_train).mean()}\")\n",
    "print(f\"Accuracy : {(neural_pred == y_train).mean()}\")\n",
    "print(f\"Same output : {(neural_pred == pred).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define our fastai Learner, with the dataset, the model, and the loss function, which is a Label Smoothing Cross Entropy here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.61'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai\n",
    "fastai.__version__\n",
    "# Need Fastai 1, NOT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:54:25.187874Z",
     "start_time": "2020-06-02T15:54:24.819611Z"
    }
   },
   "outputs": [],
   "source": [
    "from fastai.basic_data import DataBunch\n",
    "from fastai.tabular.learner import Learner\n",
    "from fastai.metrics import accuracy\n",
    "\n",
    "from fase.hnrf.tree import CrossEntropyLabelSmoothing\n",
    "import torch.nn as nn\n",
    "\n",
    "data = DataBunch(train_dl, valid_dl,fix_dl=fix_dl)\n",
    "\n",
    "criterion = CrossEntropyLabelSmoothing()\n",
    "\n",
    "learn = Learner(data, model, loss_func=criterion, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use fastai lr finder to have an idea of what learning rate to choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:54:32.246884Z",
     "start_time": "2020-06-02T15:54:26.125394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2' class='' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      50.00% [2/4 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.642940</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.593468</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='120' class='' max='163' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      73.62% [120/163 00:00<00:00 0.6740]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(num_it=500)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that a good learning rate should be around 1e-1.\n",
    "\n",
    "We can now fine tune our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:54:44.245642Z",
     "start_time": "2020-06-02T15:54:32.248618Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.533845</td>\n",
       "      <td>0.518835</td>\n",
       "      <td>0.813052</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.505172</td>\n",
       "      <td>0.504718</td>\n",
       "      <td>0.828791</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.500321</td>\n",
       "      <td>0.499961</td>\n",
       "      <td>0.834549</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.496484</td>\n",
       "      <td>0.498958</td>\n",
       "      <td>0.838580</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.496100</td>\n",
       "      <td>0.498154</td>\n",
       "      <td>0.835317</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5,1e-1 / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can have a look at the performance of the Neural Random Forest tuned with respect to the original sklearn Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T15:54:44.435307Z",
     "start_time": "2020-06-02T15:54:44.247735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy : 0.8581573896353167\n",
      "Accuracy : 0.8483685220729367\n",
      "Same output : 0.9641074856046066\n"
     ]
    }
   ],
   "source": [
    "pred = rf.predict(X_valid_normalized)\n",
    "\n",
    "with torch.no_grad():\n",
    "    neural_pred = model(torch.tensor(X_valid_normalized).float()).argmax(dim=1).numpy()\n",
    "\n",
    "print(f\"Original accuracy : {(pred == y_valid).mean()}\")\n",
    "print(f\"Accuracy : {(neural_pred == y_valid).mean()}\")\n",
    "print(f\"Same output : {(neural_pred == pred).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homomorphic Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T14:28:27.202632Z",
     "start_time": "2020-05-04T14:28:27.118290Z"
    }
   },
   "source": [
    "Now that we have seen how a Neural Random Forest can be obtained and fine tuned from a regular sklearn Random Forest, we can now see how its Homomorphic Random Forest counterpart performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do so, we must first initialize the parameters of the CKKS SEAL library, and choose the polynomial activation function we want. Here we will use the same activation function as the above Neural Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Param():\n",
    "    def __init__(self, n=None, logn=None, logp=None, logq=None, logQboot=None):\n",
    "        self.n = n\n",
    "        self.logn = logn\n",
    "        self.logp = logp\n",
    "        self.logq = logq \n",
    "        self.logQboot = logQboot\n",
    "        if self.logn == None:\n",
    "            self.logn = int(np.log2(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "logq = 540\n",
    "logp = 30\n",
    "logn = 14\n",
    "n = 1*2**logn\n",
    "\n",
    "parms = Param(n=n, logp=logp, logq=logq)\n",
    "\n",
    "do_reduction=False\n",
    "Nclass = 2\n",
    "\n",
    "ring = HEAAN.Ring()\n",
    "secretKey = HEAAN.SecretKey(ring)\n",
    "scheme = HEAAN.Scheme(secretKey, ring)# isSerialized=True로 하면 에러남. \n",
    "\n",
    "algo = HEAAN.SchemeAlgo(scheme)\n",
    "\n",
    "\n",
    "# reduction때는 right rotation N_class개 필요. \n",
    "if do_reduction:\n",
    "    scheme.addLeftRotKeys(secretKey)\n",
    "    for i in range(Nclass):\n",
    "        scheme.addRightRotKey(secretKey, i+1) # \n",
    "else:\n",
    "    # reduction 안 하면 하나짜리 rotation만 여러번 반복.\n",
    "    scheme.addLeftRotKey(secretKey, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fase.hnrf.cryptotree import HomomorphicNeuralRandomForest\n",
    "h_rf = HomomorphicNeuralRandomForest(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CKKS paramters:\n",
      "---------------------------\n",
      "n = 16384\n",
      "logp = 30\n",
      "logq = 540\n",
      "tanh activation polynomial coeffs = [-9.638754e-16  4.758149e+00  8.250976e-14 -1.838215e+01 -7.910440e-13  3.860479e+01  2.454118e-12 -3.728043e+01\n",
      " -3.008826e-12  1.331208e+01  1.268642e-12]\n",
      "tanh activation polynomial degree = 10\n",
      "\n",
      "Neural RF\n",
      "---------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(heaan_nrf)\n",
    "\n",
    "featurizer = heaan_nrf.HomomorphicTreeFeaturizer(h_rf.return_comparator(), scheme, parms)\n",
    "\n",
    "nrf_evaluator = heaan_nrf.HomomorphicTreeEvaluator.from_model(h_rf,\n",
    "                                                    scheme,\n",
    "                                                    parms,\n",
    "                                                    my_tm_tanh.coeffs,\n",
    "                                                    do_reduction = do_reduction\n",
    "                                                    )\n",
    "\n",
    "nrf_evaluator.sk = secretKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_valid_normalized[0]\n",
    "\n",
    "ctx = featurizer.encrypt(x)\n",
    "#decrypt_print(ctx)\n",
    "\n",
    "result = nrf_evaluator(ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = nrf_evaluator.decrypt(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.23402404785156253"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_645895/3990737751.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'out0' is not defined"
     ]
    }
   ],
   "source": [
    "np.sum(out0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homomophic_pred = decrypt(secretKey, result)\n",
    "np.argmax(homomophic_pred[:Nclass])\n",
    "print(homomophic_pred[:5])\n",
    "\n",
    "decrypt_print(nrf_evaluator.w1_ctx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ctx.logq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = nrf_evaluator.compare(ctx)\n",
    "\n",
    "#Compare OK\n",
    "\n",
    "decrypt_print(temp)\n",
    "\n",
    "#temp2 = nrf_evaluator.match(temp)\n",
    "\n",
    "output = nrf_evaluator._mat_mult(nrf_evaluator.w1_ctx, temp)\n",
    "\n",
    "#scheme.encrypt(b1_ctx, self.b1_hedb, n, logp, output.logq)\n",
    "print(f\"MATCH:: 'output.logq', {output.logq} == {nrf_evaluator.b1_ctx.logq}?\")\n",
    "\n",
    "decrypt_print(output)\n",
    "\n",
    "nrf_evaluator.scheme.addAndEqual(output, nrf_evaluator.b1_ctx)\n",
    "\n",
    "decrypt_print(output)\n",
    "\n",
    "temp2 = nrf_evaluator.activation(output)\n",
    "\n",
    "decrypt_print(temp2)\n",
    "\n",
    "temp3 = nrf_evaluator.decide(temp2)\n",
    "\n",
    "decrypt_print(temp3[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = nrf_evaluator.reduce(temp3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일단 reduce는 안 하는 걸로.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homomophic_pred[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp3[0].n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEAAN.Ciphertext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see what was the original output, if we had used only the Neural Random Forest : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T08:36:25.347094Z",
     "start_time": "2020-06-01T08:36:25.314333Z"
    }
   },
   "outputs": [],
   "source": [
    "x = X_train_normalized[i]\n",
    "\n",
    "pred = rf.predict_proba(x.reshape(1,-1))\n",
    "neural_pred = model(torch.tensor(x).float().unsqueeze(0))\n",
    "\n",
    "print(f\"Original Random Forest output : {pred}\")\n",
    "print(f\"Neural Random Forest output : {neural_pred.detach()}\")\n",
    "print(f\"Homomorphic Random Forest output : {homomorphic_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see our Neural Random Forest, and Homomorphic Random Forest have very similar outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison between models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now compare a linear model, a RF, a NRF and a HRF. \n",
    "\n",
    "Because computation are done one at a time with HRF, we will use Fastai `parallel` to speedup inference taking advantage of the multiple CPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T16:03:07.073814Z",
     "start_time": "2020-06-02T15:55:11.698789Z"
    }
   },
   "outputs": [],
   "source": [
    "from fastai.core import parallel\n",
    "import multiprocessing\n",
    "\n",
    "def predict(x, index):\n",
    "    \"\"\"Performs HRF prediction\"\"\"\n",
    "    \n",
    "    # We first encrypt and evaluate our model on it\n",
    "    ctx = homomorphic_featurizer.encrypt(x)\n",
    "    outputs = tree_evaluator(ctx)\n",
    "    \n",
    "    # We then decrypt it and get the first 2 values which are the classes scores\n",
    "    # ptx = seal.Plaintext()\n",
    "    ptx = decryptor.decrypt(outputs)\n",
    "    \n",
    "    homomorphic_pred = encoder.decode(ptx)[:2]\n",
    "    homomorphic_pred = np.argmax(homomorphic_pred)\n",
    "    \n",
    "    return index, homomorphic_pred\n",
    "\n",
    "# We get the number of cores\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "n_example = 320\n",
    "\n",
    "# We compute the outputs\n",
    "hrf_pred = parallel(predict, X_valid_normalized[:n_example,:], max_workers=cores)\n",
    "\n",
    "# Because the outputs are unordered we must first sort by index then take the predictions\n",
    "hrf_pred = np.array(sorted(hrf_pred, key = lambda x:x[0]))[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the predictions of the NRF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "\n",
    "for x,y in valid_dl:\n",
    "    with torch.no_grad():\n",
    "        pred = model(x)\n",
    "    outputs.append(pred)\n",
    "    \n",
    "nrf_pred = torch.cat(outputs).argmax(dim=1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we compute the predictions of logistic regression and RF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T15:20:09.451303Z",
     "start_time": "2020-06-05T15:20:09.130581Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "linear = LogisticRegression()\n",
    "linear.fit(X_train_normalized, y_train)\n",
    "\n",
    "# We compute the linear preds\n",
    "linear_pred = linear.predict(X_valid_normalized)\n",
    "\n",
    "# We compute the random forest predictions\n",
    "rf_pred = rf.predict(X_valid_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute all metrics now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T16:34:08.563287Z",
     "start_time": "2020-06-02T16:34:08.526218Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def compute_metrics(pred, y):\n",
    "    \"\"\"Computes all the metrics between predictions and real values\"\"\"\n",
    "    accuracy = accuracy_score(pred,y)\n",
    "    precision = precision_score(pred,y)\n",
    "    recall = recall_score(pred,y)\n",
    "    f1 = f1_score(pred, y)\n",
    "    return dict(accuracy=accuracy, precision=precision, recall=recall, f1=f1)\n",
    "\n",
    "models = dict(nrf=nrf_pred, hrf=hrf_pred, rf=rf_pred, linear=linear_pred)\n",
    "\n",
    "outputs = []\n",
    "for name, pred in models.items():\n",
    "    metrics = compute_metrics(pred[:n_example], y_valid[:n_example])\n",
    "    metrics[\"model\"] = name\n",
    "    outputs.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T16:34:10.375109Z",
     "start_time": "2020-06-02T16:34:10.358017Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs = pd.DataFrame(outputs)\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T16:34:34.900805Z",
     "start_time": "2020-06-02T16:34:34.882706Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs.to_csv(\"results.csv\", index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can have a look at how similar NRF and HRF predictions are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrf_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrf_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrf_pred == hrf_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(nrf_pred == hrf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T16:34:36.991805Z",
     "start_time": "2020-06-02T16:34:36.974070Z"
    }
   },
   "outputs": [],
   "source": [
    "np.sum(nrf_pred == hrf_pred)/len(hrf_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting featurizer and models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now see how we can export the model and the featurizer for the server and the client."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessing pipeline can be saved for later use on the client side. We can save and load it with pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T17:26:27.937262Z",
     "start_time": "2020-05-15T17:26:27.899744Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(pipe, open(\"pipe.pkl\", \"wb\"))\n",
    "pipe = pickle.load(open(\"pipe.pkl\" , \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also store as well the featurizer, used to shuffle the features before the comparisons. This will be sent to the client side to prepare the data before sending it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T17:26:27.976904Z",
     "start_time": "2020-05-15T17:26:27.944267Z"
    }
   },
   "outputs": [],
   "source": [
    "homomorphic_featurizer.save(\"homomorphic_featurizer.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can store the Homomorphic Random Forest to use on the server side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T17:26:28.025277Z",
     "start_time": "2020-05-15T17:26:27.981667Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(h_rf, open(\"h_rf.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the demo built using Streamlit, we need to know what were the values of the categorical features, and also one example of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T17:26:28.114617Z",
     "start_time": "2020-05-15T17:26:28.028703Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in X_train.columns.values:\n",
    "    if col in categorical_columns:\n",
    "        X_train[col] = X_train[col].astype(\"category\")\n",
    "    else:\n",
    "        X_train[col] = X_train[col].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T17:26:28.168300Z",
     "start_time": "2020-05-15T17:26:28.118573Z"
    }
   },
   "outputs": [],
   "source": [
    "example = X_train.iloc[[0]]\n",
    "example.to_csv(\"example.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T17:26:28.213964Z",
     "start_time": "2020-05-15T17:26:28.177644Z"
    }
   },
   "outputs": [],
   "source": [
    "dtypes = X_train.dtypes\n",
    "pickle.dump(dtypes, open(\"dtypes.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T17:26:28.260417Z",
     "start_time": "2020-05-15T17:26:28.217860Z"
    }
   },
   "outputs": [],
   "source": [
    "dtypes = pickle.load(open(\"dtypes.pkl\", \"rb\"))\n",
    "dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T16:03:13.395533Z",
     "start_time": "2020-06-02T16:03:13.378822Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "274.9px",
    "width": "214px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
